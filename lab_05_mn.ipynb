{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metode Iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiție și clasificare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodele iterative sunt tehnici care obțin soluțiile unui sistem liniar prin aproximări succesive la fiecare pas. Acestea sunt de două feluri, staționare și nestaționare. \n",
    "\n",
    "Cele __staționare__ sunt metode mai vechi apărute, ușor de înțeles și de implementat. Acestea presupun ca la fiecare pas să se execute aceleași operații pe vectorul curent care reține soluția. În acest laborator vom discuta despre __Jacobi, Gauss-Seidel și suprarelaxare__ în cadrul metodelor iterative staționare.\n",
    "\n",
    "Metodele __nestaționare__ sunt mai nou apărute, mai greu de implementat, dar mai eficiente. Nu vor fi acoperite în acest laborator, dar ca exemplu am putea menționa metoda gradientului conjugat/biconjugat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum funcționează?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodele iterative se bazează pe aproximări succesive. Să presupunem că avem de rezolvat sistemul __Ax = b__. Începem rezolvarea cu o aproximare inițială $x = x_0$. La pasul i, calculăm o nouă aproximare, bazată pe cea de la pasul anterior. Astfel, se obține un șir de aproximări $x_0, x_1, x_2, ..., x_k, ...$. Cu cât permitem mai multe iterații, cu atât solutia este mai bună. Cu alte cuvinte, cu cât indicele lui x este mai mare, cu atât se apropie mai mult de adevărata soluție a ecuației __Ax = b__. Deci, când k -> $\\infty$, șirul de soluții converge la soluția __x = $A^{-1}$b__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forma matriceală a soluției este: <br>\n",
    "x$^{k + 1}$ = G * x$^k$ + c, k = 0, 1, 2... <br>\n",
    "unde x$^{k}$ și x$^{k + 1}$ repezintă aproximările la pașii k si k + 1, <br>\n",
    "__G__ este matricea de iterație, iar **c** este un vector coloană ce vor fi explicate mai jos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum știu că am găsit soluția?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul metodelor iterative nu căutăm soluția exactă, ci căutăm o aprximare cât mai bună a acesteia. Cu cât parcurgem mai multe iterații, cu atât obținem cu aproximare mai bună, însă cum știm că ne putem opri din căutare? \n",
    "\n",
    "Ne oprim când o soluție nu diferă foarte mult de precedenta, deci când sunt suficient de apropiate. Noi stabilim când se întâmplă asta, alegând un epsilon destul de mic, de exemplu 0.001 sau 0.0001. Formula după care ne ghidăm este: \n",
    "$|x^{k + 1} - x^{k}| < ebs$\n",
    "\n",
    "#### Observație: \n",
    "Numărul de zerouri dupa virgulă în valoarea lui epsilon oferă precizie. Epsilon = 0.001 oferă o precizie de două zecimale exacte, pe cand 0.0001 oferă trei zecimale exacte.\n",
    "\n",
    "O altă condiție de oprire ar putea fi atingerea numărului maxim de iterații, chiar dacă nu am găsit o aproximare suficient de bună pentru sistemul dat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prea multă teorie, ce se face mai concret? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pornind de la sistemul __Ax = b__, scriem matricea A ca diferență de două matrici, A = N - P.\n",
    "Sistemul este prelucrat astfel: <br>\n",
    "(N - P)x = b <br>\n",
    "Nx - Px = b <br>\n",
    "Nx = Px + b | * N$^{-1}$ <br>\n",
    "x = N$^{-1}$Px + N$^{-1}$b <br>\n",
    "x = Gx + c (doar notații)\n",
    "\n",
    "G este matricea de iterație de care vorbeam mai devreme, care aparține lui R$^{nxn}$, iar c este un vector coloană din R$^n$.\n",
    "\n",
    "#### Condiție de convergență:\n",
    "${\\rho(G)} < 1$, unde ${\\rho(G)} = max|{\\lambda}_{i}|$, numită raza spectrală\n",
    "\n",
    "Pentru Gauss-Seidel, putem arăta convergență și dacă demonstrăm că matricea G este diagonal dominantă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matricile __N__ și **P** sunt calculate, de la o metodă la alta, în funcție de matricea D (diagonala lui A), L (matricea formată din elementele de sub diagonala principală a lui A) și U (matricea formată din elementele de deasupra diagonalei principale a lui A). \n",
    "\n",
    "#### Exemplu:\n",
    "Fie matricea A = \n",
    "$\\begin{bmatrix}\n",
    "    1 & 5 & -3 \\\\\n",
    "    6 & 10 & 2 \\\\\n",
    "    -1 & 7 & 8 \\\\ \n",
    "    \\end{bmatrix}$ <br>\n",
    "    \n",
    "Să calculăm D, L si U:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 5 -3; 6 10 2; -1 7 8]\n",
    "D = diag(diag(A))\n",
    "L = tril(A, -1)\n",
    "U = triu(A, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gauss-Seidel este o metodă iterativă similară cu Jacobi, discutată anterior. Diferența între ele este că Jacobi calculează soluția de la pasul i + 1 bazându-se în totalitate pe soluția de la pasul i, pe cand Gauss-Seidel se bazează pe soluțiile de la ambii pași.\n",
    "\n",
    "Mai clar, să zicem ca $x_0 = (a_0, b_0, c_0)$ este soluția inițială și $x_1 = (a_1, b_1, c_1)$ soluția următoare.\n",
    "La pasul 1, Jacobi ar calcula $a_1$ în funcție de $a_0$, $b_0$ și $c_0$. De asemenea, ar calcula și $b_1$ și $c_1$ tot în funcție de $a_0$, $b_0$ și $c_0$.\n",
    "Gauss-Seidel începe prin a calcula $a_1$ în funcție de $a_0$, $b_0$ și $c_0$, deoarece nu cunoaște alte valori. Însă pentru $b_1$ folosește, în loc de $a_0$, valoarea lui $a_1$ calculată pentru soluția de la pasul curent. Astfel, $b_1$ e calculat după $a_1$, $b_0$ și $c_0$, iar $c_1$ e calculată după $a_1$, $b_1$ și $c_0$.\n",
    "\n",
    "#### Observație\n",
    "Gauss-Seidel converge mai repede decât Jacobi, adică găsește o soluție suficient de bună, care să satisfacă relația cu epsilon, în mai puțini pași."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulele de la Gauss-Seidel\n",
    "\n",
    "Pornind de la Ax = b și A = N - P, alegem N = D - L și P = U. <br> Atfel, G = (D - L)$^{-1}$U\n",
    "\n",
    "Soluția recurentă a sistemului este: <br>\n",
    "$$x_i^{p + 1} = \\frac{b_i - \\sum_{j = 1}^{i - 1} a_{ij}x_j^{p + 1} - \\sum_{j = i + 1}^{n} a_{ij}x_j^{p}}{a_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Exemplu in care G nu converge\n",
    "\n",
    "N = D - L\n",
    "P = U\n",
    "G = inv(D - L)*U\n",
    "rs = max(abs(eig(G))) % raza spectrala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Exemplu in care G converge\n",
    "\n",
    "A = [1 1 -3; 6 10 2; -1 7 8]\n",
    "D = diag(diag(A))\n",
    "L = tril(A, -1)\n",
    "U = triu(A, 1)\n",
    "\n",
    "N = D - L\n",
    "P = U\n",
    "G = inv(D - L)*U\n",
    "rs = max(abs(eig(G))) % raza spectrala\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiu: completați codul de la Gauss-Seidel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [-1 2 3]\n",
    "x0 = [0 0 0]\n",
    "tol = 0.001\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [x step] = GaussSeidel(A, b, x0, tol, max_iter)\n",
    "\n",
    "    % TODO 1: Calculeaza matricile N, P si G\n",
    "    \n",
    "    \n",
    "    % TODO 2: Verifica daca G converge. Afiseaza un mesaj corespunzator daca nu.\n",
    "\n",
    "    n = length(b);\n",
    "    x = x0;\n",
    "    % iterate to the maximum number of iterations\n",
    "    for step = 1 : max_iter\n",
    "        % iterate through every x(i)\n",
    "        for i = 1 : n\n",
    "            % TODO 3: Calculeaza suma valorilor gasite de la pasul curent\n",
    "\n",
    "            % TODO 4: Calculeaza suma valorilor de care mai avem nevoie de la pasul anterior\n",
    "\n",
    "            % TODO 5: Aplica formula recurenta\n",
    "        endfor\n",
    "\n",
    "        % TODO 6: Verifica daca s-a ajuns la o solutie suficient de buna folosind functia norm\n",
    "        \n",
    "        % Updatam solutia \n",
    "        x0 = x;\n",
    "    endfor\n",
    "endfunction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
